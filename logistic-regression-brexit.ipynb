{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1)Fit a logistic regression models using all of the available inputs. Identify the direction of each effect from the fitted coefficients. Compare these with the plots shown on the Guardian website. Do they agree? Explain.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   No. Observations:                  344\n",
      "Model:                            GLM   Df Residuals:                      338\n",
      "Model Family:                Binomial   Df Model:                            5\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -123.69\n",
      "Date:                Thu, 23 Mar 2023   Deviance:                       247.39\n",
      "Time:                        12:12:40   Pearson chi2:                     401.\n",
      "No. Iterations:                     6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -0.1386      0.848     -0.164      0.870      -1.800       1.523\n",
      "X[0]          17.5780      2.911      6.038      0.000      11.872      23.284\n",
      "X[1]          -6.3857      1.922     -3.323      0.001     -10.152      -2.619\n",
      "X[2]           5.9209      1.407      4.209      0.000       3.164       8.678\n",
      "X[3]         -26.7443      3.576     -7.478      0.000     -33.753     -19.735\n",
      "X[4]           5.6861      1.803      3.153      0.002       2.152       9.221\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "from statsmodels.formula.api import glm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data = pd.read_csv(r\"C:\\Users\\hughd\\Desktop\\machine learning\\brexit.csv\")\n",
    "data['voteBrexit'] = data['voteBrexit'].astype(int)\n",
    "# create the Y variable\n",
    "Y = data['voteBrexit']\n",
    "\n",
    "# create the X variable\n",
    "x_data = ['abc1', 'medianIncome', 'medianAge', 'withHigherEd', 'notBornUK']\n",
    "X = data[x_data]\n",
    "\n",
    "# create a logistic regression model with a binomial distribution and a logit link function\n",
    "myglm = glm('Y ~ X', data=X, family=sm.families.Binomial()).fit()\n",
    "\n",
    "print(myglm.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X[0] = 'abc1', X[1] = 'medianIncome', X[2] = 'medianAge', X[3] = 'withHigherEd', X[4] = 'notBornUK'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'medianIncome' and 'withHigherEd' are both negative in direction. Therefore they both voted for remain comparitively to the other variables. This differs from the plots on the guardian website that claim only the 'medianAge' was remain. This is likely due that they used each catagory individually rather than all together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2)Present the value of each coefficient estimate and calculate the 95% confidence interval. Which input would you say has the strongest effect and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coeffs are listed below:\n",
      "Intercept    -0.138596\n",
      "X[0]         17.577998\n",
      "X[1]         -6.385740\n",
      "X[2]          5.920877\n",
      "X[3]        -26.744259\n",
      "X[4]          5.686138\n",
      "dtype: float64\n",
      "\n",
      "CI values are: \n",
      "Min CI values are: \n",
      "Intercept    -1.799992\n",
      "X[0]         11.871724\n",
      "X[1]        -10.152204\n",
      "X[2]          3.164067\n",
      "X[3]        -33.753456\n",
      "X[4]          2.151669\n",
      "dtype: float64\n",
      "\n",
      "Min CI values are: \n",
      "Intercept     1.522799\n",
      "X[0]         23.284272\n",
      "X[1]         -2.619275\n",
      "X[2]          8.677687\n",
      "X[3]        -19.735062\n",
      "X[4]          9.220608\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats\n",
    "import numpy as np\n",
    "zc = scipy.stats.norm.ppf(0.975)\n",
    "\n",
    "\n",
    "estimate = myglm.params\n",
    "    \n",
    "stderr = myglm.bse\n",
    "   \n",
    "CI_min = estimate-zc*stderr\n",
    "CI_max = estimate+zc*stderr\n",
    "print('coeffs are listed below:')\n",
    "print(estimate)\n",
    "print('\\nCI values are: ')    \n",
    "print('Min CI values are: ') \n",
    "print(CI_min)\n",
    "print('\\nMin CI values are: ') \n",
    "print(CI_max)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X[0] = 'abc1', X[1] = 'medianIncome', X[2] = 'medianAge', X[3] = 'withHigherEd', X[4] = 'notBornUK'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Aic 'withHigherEd' was the most significant variable when comparing which value was most important in determining trends. One reason this might be the case, is the fact that, the coefficient has the largest vale from zero making it the most significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 3)Using aic, perform a model selection to determine which factors are useful to predict the result of the vote. You can use a ‘greedy’ input selection procedure, as follows: (i) select the best model with 1 input; (ii) fixing that input, select the best two-input model (i.e. try all the other 4 inputs with the one you selected first); (iii) select the best three-input model containing the first two inputs you chose, etc. At each stage evaluate the quality of fit using aic and stop if this gets worse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected variables: ['withHigherEd']\n",
      "AIC value: 313.560\n",
      "Selected variables: ['withHigherEd', 'abc1']\n",
      "AIC value: 286.545\n",
      "Selected variables: ['withHigherEd', 'abc1', 'medianAge']\n",
      "AIC value: 271.932\n",
      "Selected variables: ['withHigherEd', 'abc1', 'medianAge', 'medianIncome']\n",
      "AIC value: 266.949\n",
      "Selected variables: ['withHigherEd', 'abc1', 'medianAge', 'medianIncome', 'notBornUK']\n",
      "AIC value: 259.385\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "from statsmodels.formula.api import glm\n",
    "\n",
    "\n",
    "data = pd.read_csv(r\"C:\\Users\\hughd\\Desktop\\machine learning\\brexit.csv\")\n",
    "Y = data['voteBrexit']\n",
    "x_data = ['abc1', 'medianIncome', 'medianAge', 'withHigherEd', 'notBornUK']\n",
    "\n",
    "\n",
    "select_cat = []\n",
    "aic_values = []\n",
    "\n",
    "for i in range(0, len(x_data)):\n",
    "    best_aic = float('inf')\n",
    "    best_cat = None\n",
    "    \n",
    "   \n",
    "    for cat in x_data:\n",
    "        if cat not in select_cat:\n",
    "            \n",
    "            select_cat.append(cat)\n",
    "            \n",
    "           \n",
    "            formula = 'Y ~ ' + ' + '.join(select_cat)\n",
    "            myglm = glm(formula, data, family=sm.families.Binomial()).fit()\n",
    "           \n",
    "            aic = myglm.aic\n",
    "            \n",
    "           \n",
    "            if aic < best_aic:\n",
    "                best_aic = aic\n",
    "                best_cat = cat\n",
    "            \n",
    "            \n",
    "            select_cat.pop()\n",
    "    \n",
    "   \n",
    "    if i > 1 and best_aic > aic_values[-1]:\n",
    "        break\n",
    "    \n",
    "   \n",
    "    select_cat.append(best_cat)\n",
    "    \n",
    "  \n",
    "    aic_values.append(best_aic)\n",
    "    \n",
    "    \n",
    "    print(f\"Selected variables: {select_cat}\")\n",
    "    print(f\"AIC value: {best_aic:.3f}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 4)Use the Scikit-Learn package to create a decision tree classification model. Visualise your model and intepret the fitted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(X, Y)\n",
    "\n",
    "\n",
    "export_graphviz(tree, out_file='dot_data', feature_names=x_data, class_names=['Remain', 'Leave'], filled=True, rounded=True)\n",
    "\n",
    "\n",
    "!dot -Tpng dot_data -o tree_file1.png\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./tree_file1.png\" width=1500, alt=\"test\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the tree the only factor that was more dominant towards remain was 'medianAge' all the other factors were in favor of leave. The program starts with the most important factor 'withHigherEd' and branches out trying diffrent factors and diffrent combinations of factors until effects of the vote are fully visualised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 5)Compare your decision tree model and your logistic regression model. Do they attribute high importance to the same factors? How do you intepret each model to explain the referendum vote?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       variable  importance value\n",
      "0          abc1          0.178019\n",
      "1  medianIncome          0.143207\n",
      "2     medianAge          0.132994\n",
      "3  withHigherEd          0.419795\n",
      "4     notBornUK          0.125985\n"
     ]
    }
   ],
   "source": [
    "importance=pd.DataFrame({'variable': ['abc1', 'medianIncome', 'medianAge', 'withHigherEd', 'notBornUK'],'importance value': tree.feature_importances_})\n",
    "print(importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the tree and the logistic regression model do not agree on the importance of every factor 'withHigherEd' was definetly the most important factor for the vote as both models rated this as the most important by a significant margin. The logistic regression model had two factors that were for remain, 'medianIncome' and 'withHigherEd'. The tree however had both of these factors for leave and only 'medianAge' was for remain. Something that both models do agree on is the order of importance of each factor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 6)Which model would you use if you were explaining the results for a newspaper article, and why? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Personally I would choose the logistic regression model for a newspaper article. Although the tree method has a visual representation of the results, I think that it is much too confusing to read and interpret, especially as a average reader. Although the logistic method has no visualisation, I think that the direction of the sign is much easier to interpret especially with the explaination that would go with the article. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
